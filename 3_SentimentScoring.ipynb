{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3898892d7e34557bb8499aff9aa0ccd3bf7bab375649613f01d0952879e4c360"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from afinn import Afinn\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "afinn_df = pd.read_csv(\"data/AFINN-en-165.tsv\", sep=\"\\t\", header=None, names=[\"word\", \"score\"])\n",
    "#afinn_df\n",
    "afinn = Afinn()\n",
    "\n",
    "vad_df = pd.read_csv(\"data/NRC-VAD-Lexicon.tsv\", sep=\"\\t\")\n",
    "#vad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_scores = dict(zip(afinn_df[\"word\"], afinn_df[\"score\"]))\n",
    "#afinn_scores[\"yummy\"]\n",
    "def afinn_score(text):\n",
    "    return sum(afinn_scores.get(t.lemma_, 0) for t in nlp(text))\n",
    "\n",
    "word_valence = dict(zip(vad_df[\"Word\"], vad_df[\"Valence\"]))\n",
    "word_arousal = dict(zip(vad_df[\"Word\"], vad_df[\"Arousal\"]))\n",
    "word_dminanc = dict(zip(vad_df[\"Word\"], vad_df[\"Dominance\"]))\n",
    "\n",
    "def text_valence(text, agg=sum):\n",
    "    return agg([word_valence.get(t.lemma_, 0) for t in nlp(text)])\n",
    "\n",
    "def text_arousal(text, agg=sum):\n",
    "    return agg([word_arousal.get(t.lemma_, 0) for t in nlp(text)])\n",
    "\n",
    "def text_dminanc(text, agg=sum):\n",
    "    return agg([word_dminanc.get(t.lemma_, 0) for t in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweetDf = pd.read_csv(\"data/500000tweetshydrated.tsv\", sep=\"\\t\")\n",
    "tweetDf[\"full_text\"] = tweetDf[\"full_text\"].astype(\"string\")\n",
    "#tweetDf.dtypes\n",
    "#print(tweetDf.full_text)\n",
    "#tweetDf[\"wordList\"] = wordList(tweetDf[\"full_text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counting = 0\n",
    "score = []\n",
    "for index, row in tweetDf.iterrows():\n",
    "    #print(row['full_text'], afinn.score(row['full_text']))\n",
    "    score.append([\n",
    "        row['Datetime'],\n",
    "        afinn_score(row['full_text']),\n",
    "        afinn.score(row['full_text']),\n",
    "        text_valence(row['full_text']),\n",
    "        text_arousal(row['full_text']),\n",
    "        text_dminanc(row['full_text']),\n",
    "        text_valence(row['full_text'], agg=np.mean),\n",
    "        text_arousal(row['full_text'], agg=np.mean),\n",
    "        text_dminanc(row['full_text'], agg=np.mean),\n",
    "        row['full_text'],\n",
    "        wordList(row['full_text'])\n",
    "        ])\n",
    "    counting+=1\n",
    "    if (counting % 1000 == 0): print(counting/len(tweetDf.index)*100, '%,', counting, '/', len(tweetDf.index))\n",
    "    if counting == 100: break\n",
    "\n",
    "scoredf = pd.DataFrame(score, columns = ['date','AfinnSentiment','AfinnDefaultSentiment','NRCValence','NRCArousal','NRCDominance','NRCValenceMean','NRCArousalMean','NRCDominanceMean','fulltext','lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredf.to_csv(\"data/500000TweetsHydratedScored.tsv\",index = False,sep='\\t',line_terminator='\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordList(tText):\n",
    "    \n",
    "    doc = nlp(tText)\n",
    "    ### TOKENIZING ###\n",
    "    ### REMOVING STOP WORDS ###\n",
    "    wList = [token for token in doc if not token.is_stop]\n",
    "    ### NORMALIZING ###\n",
    "        ### STEMMING ###\n",
    "        ### LEMMATIZATION ###\n",
    "    wList = [token.lemma_ for token in wList]\n",
    "    ### REMOVE PUNCTUATION ###\n",
    "    punctuations=\"?:!.,;\"\n",
    "    for word in wList:\n",
    "        if word in punctuations:\n",
    "            wList.remove(word)\n",
    "    ### POS filtering ###\n",
    "    \n",
    "    wString = \"\"\n",
    "    for each in wList:\n",
    "        wString += each + \" \"\n",
    "    return wString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}